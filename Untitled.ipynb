{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "# Import Splinter and set the chromedriver path\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "\n",
    "# Module used to connect Python with MongoDb\n",
    "import pymongo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. \n",
    "# Assign the text to variables that you can reference later.\n",
    "\n",
    "# URL of page to be scraped\n",
    "url_nasa = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "\n",
    "# executable path and browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "browser.visit(url_nasa)\n",
    "\n",
    "# Retrieve page with the requested module\n",
    "#response = requests.get(url_nasa)\n",
    "\n",
    "# Create Beatifulsoup object; pase with 'html.parser' or 'lxml'\n",
    "soup = bs(browser.html, 'html.parser')\n",
    "\n",
    "# Examine the results, then determine element that contains the info needed\n",
    "#print(soup.prettify()) #Note: it was very useful to print the first time, afterwards it is impractical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. \n",
    "# Assign the text to variables that you can reference later.\n",
    "# Results are returned as an iterable list\n",
    "nasa_news_results = soup.find_all('li', class_='slide')  \n",
    "#print(nasa_news_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The default port used by MongoDB is 27017\n",
    "# https://docs.mongodb.com/manual/reference/default-mongodb-port/\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Define database and collection\n",
    "db = client.nasaNews_db\n",
    "collection = db.items\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response = requests.get(url_nasa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "March 26, 2020\n",
      "10.9 Million Names Now Aboard NASA's Perseverance Mars Rover\n",
      "As part of NASA's 'Send Your Name to Mars' campaign, they've been stenciled onto three microchips along with essays from NASA's 'Name the Rover' contest. Next stop: Mars.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loop through returned results\n",
    "for result in nasa_news_results:\n",
    "    try:\n",
    "        nasa_news = result.find('div', class_= 'image_and_description_container')\n",
    "        date = nasa_news.find('div', class_='list_date').text\n",
    "        title = result.find('div', class_='content_title').text\n",
    "        paragraph = nasa_news.find('div', class_='article_teaser_body').text\n",
    "        \n",
    "        if (date and title and paragraph):\n",
    "            print('------------------------')\n",
    "            print(date)\n",
    "            print(title)\n",
    "            print(paragraph)\n",
    "            \n",
    "             # Dictionary to be inserted as a MongoDB document\n",
    "            post = {\n",
    "                'date': date,\n",
    "                'title': title,\n",
    "                'paragraph': paragraph\n",
    "            }\n",
    "\n",
    "            collection.insert_one(post)\n",
    "              \n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
